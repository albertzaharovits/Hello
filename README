README spmm-puzzle (REVISIONED)
Albert Zaharovits albert.zaharovits@gmail.com
24.4.2013

	The kernel is build using the guidelines from nvidia cuda reduce documentation[1].
	The main optimization concerns are:
		- do the reduce op in shared memory
		- avoid shared memory interleaved addresing
		- avoid warp divergence
		- each thread does it's first reduce during load in shared memory;
			therefore the kernel is exploiting device bandwidth
		- coalesce global memory access
		- avoid barriers for workgroups smaller than the warp size (unroll last loops)

	The algorithm copies parts of the array from global memory to shared memory.
	Each such part is reduced by a workgroup in shared memory, then it is placed
	in a __global buffer(__global char *g_odata). This __global buffer is the
	input buffer for a second kernel enqueue. As there are only 2 values to
	reduce this should have certainly be done on the cpu on the real thing.

	IMPORTANT NOTE: viennacl::ocl::kernel.global_work_size(0, 128) sets the number 
			of TOTAL THREADS to 128, as oposed to setting the number of work 
			groups to 128 (at least for the NVIDIA opencl implementation); 

[1] http://developer.download.nvidia.com/assets/cuda/files/reduction.pdf
